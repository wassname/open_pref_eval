{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook, is looking at way to compare the logits, logprobs, and logs of chosen completions. We hope to find a way this is more information rich than accuracy and can differentiate between the models better\n",
    "\n",
    "it should\n",
    "- be like accuracy (0 to 1)\n",
    "- be able to differentiate between models well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from datasets import Dataset, features\n",
    "import tempfile\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from typing import Optional\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from open_pref_eval.trainer import dummy_dataset, OPEConfig\n",
    "from open_pref_eval.evaluation import eval_dpo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom trainer that return full logits, so I can practice....\n",
    "class OPETrainer2(DPOTrainer):\n",
    "\n",
    "    @staticmethod\n",
    "    def get_batch_logps(\n",
    "        logits: torch.FloatTensor,\n",
    "        labels: torch.LongTensor,\n",
    "        label_pad_token_id: int = -100,\n",
    "        is_encoder_decoder: bool = False,\n",
    "    ) -> Tuple[torch.FloatTensor, torch.LongTensor]:\n",
    "        if logits.shape[:-1] != labels.shape:\n",
    "            raise ValueError(\"Logits (batch and sequence length dim) and labels must have the same shape.\")\n",
    "\n",
    "        if not is_encoder_decoder:\n",
    "            labels = labels[:, 1:].clone()\n",
    "            logits = logits[:, :-1, :]\n",
    "        loss_mask = labels != label_pad_token_id\n",
    "\n",
    "        # dummy token; we'll ignore the losses on these tokens later\n",
    "        labels[labels == label_pad_token_id] = 0\n",
    "\n",
    "        per_token_logps = torch.gather(logits.log_softmax(-1), dim=2, index=labels.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        return per_token_logps, loss_mask\n",
    "\n",
    "\n",
    "    def concatenated_forward(\n",
    "        self, model, batch):\n",
    "\n",
    "        concatenated_batch = self.concatenated_inputs(\n",
    "            batch,\n",
    "            is_encoder_decoder=self.is_encoder_decoder,\n",
    "            is_vision_model=self.is_vision_model,\n",
    "            label_pad_token_id=self.label_pad_token_id,\n",
    "            padding_value=self.padding_value,\n",
    "            device=self.accelerator.device,\n",
    "        )\n",
    "        len_chosen = batch[\"chosen_labels\"].shape[0]\n",
    "\n",
    "        model_kwargs = {}\n",
    "\n",
    "        if self.is_encoder_decoder:\n",
    "            model_kwargs[\"labels\"] = concatenated_batch[\"concatenated_labels\"]\n",
    "            model_kwargs[\"decoder_input_ids\"] = concatenated_batch.pop(\"concatenated_decoder_input_ids\", None)\n",
    "\n",
    "        if self.is_vision_model:\n",
    "            model_kwargs[\"pixel_values\"] = concatenated_batch[\"pixel_values\"]\n",
    "            model_kwargs[\"pixel_attention_mask\"] = concatenated_batch[\"pixel_attention_mask\"]\n",
    "\n",
    "        if self.aux_loss_enabled:\n",
    "            model_kwargs[\"output_router_logits\"] = True\n",
    "\n",
    "        outputs = model(\n",
    "            concatenated_batch[\"concatenated_input_ids\"],\n",
    "            attention_mask=concatenated_batch[\"concatenated_attention_mask\"],\n",
    "            use_cache=False,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        all_logits = outputs.logits\n",
    "\n",
    "        all_logps, mask = self.get_batch_logps(\n",
    "            all_logits,\n",
    "            concatenated_batch[\"concatenated_labels\"],\n",
    "            # average_log_prob=self.loss_type == \"ipo\",\n",
    "            is_encoder_decoder=self.is_encoder_decoder,\n",
    "            label_pad_token_id=self.label_pad_token_id,\n",
    "        )\n",
    "\n",
    "        chosen_logps = all_logps[:len_chosen]\n",
    "        rejected_logps = all_logps[len_chosen:]\n",
    "\n",
    "        chosen_mask = mask[:len_chosen]\n",
    "        rejected_mask = mask[len_chosen:]\n",
    "\n",
    "        chosen_logits = all_logits[:len_chosen]\n",
    "        rejected_logits = all_logits[len_chosen:]\n",
    "\n",
    "        return (chosen_logps, rejected_logps, chosen_logits, rejected_logits, chosen_mask, rejected_mask)\n",
    "    # concatenated_forward\n",
    "\n",
    "def get_dummy_trainer2(model=None, tokenizer=None, model_name:Optional[str]=None, per_device_eval_batch_size=8, **kwargs):\n",
    "    \"\"\"\n",
    "    Make a dummy trainer, \n",
    "\n",
    "    For keyword arguments, see \n",
    "    - [transformers.TrainingArguments](https://huggingface.co/docs/transformers/v4.43.3/en/main_classes/trainer#transformers.TrainingArguments)\n",
    "    - [trl.DPOConfig](https://huggingface.co/docs/trl/main/en/dpo_trainer#trl.DPOConfig)\n",
    "\n",
    "    \"\"\"\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        training_args = OPEConfig(\n",
    "            output_dir=tmp_dir,\n",
    "            per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "            loss_type='dpo',\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    if model_name is not None:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    if model is None:\n",
    "        raise ValueError('model or model_name must be provided')\n",
    "\n",
    "    # we rse a TRL class\n",
    "    trainer = OPETrainer2(\n",
    "        model=model,\n",
    "        ref_model=None,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=dummy_dataset,\n",
    "        eval_dataset=dummy_dataset,\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import AutoPeftModelForCausalLM, get_peft_model, PeftConfig, PeftModelForCausalLM\n",
    "model_name = \"gepardzik/LLama-3-8b-rogue-lora\"\n",
    "peft_config = PeftConfig.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model = PeftModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    model_name, config=peft_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f1743aee254c9eb5104acab182e1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796caef8a9314036aaba0d434614e655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.OPETrainer2 at 0x7ce044f2c890>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = get_dummy_trainer2(model=model, tokenizer=tokenizer, per_device_eval_batch_size=6)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_pref_eval.evaluation import eval_dpo_dataset, load_dataset, ds2name, is_peft_model, is_peft_model, set_adapter\n",
    "from trl import DPOTrainer\n",
    "from typing import Optional, List, Union\n",
    "from datasets import Dataset\n",
    "from contextlib import contextmanager, nullcontext\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def extract_logps(trainer, model, batch, step):\n",
    "    bs = batch['chosen_input_ids'].shape[0]\n",
    "    i = bs * step + torch.arange(bs)\n",
    "    \n",
    "    (chosen_logps, rejected_logps, chosen_logits, rejected_logits, chosen_mask, rejected_mask) = trainer.concatenated_forward(model, batch)\n",
    "\n",
    "    # Note: if we are using ipo or reprpo this will be adjusted for length, but otherwise not which would bias the results\n",
    "    # logratio = chosen_logps-rejected_logps\n",
    "\n",
    "    # turn into list of dicts\n",
    "    n = dict(\n",
    "        # logps\n",
    "        # _logratio=logratio.detach().cpu().float().numpy(),\n",
    "        _chosen_logps=chosen_logps.detach().cpu().float(),\n",
    "        _rejected_logps=rejected_logps.detach().cpu().float(),\n",
    "\n",
    "        # masks\n",
    "        _chosen_mask=chosen_mask.detach().cpu().float(),\n",
    "        _rejected_mask=rejected_mask.detach().cpu().float(),\n",
    "\n",
    "        # completion length, for checking if the model is biased\n",
    "        # _l_chosen=(batch['chosen_labels']>0).sum(-1).detach().cpu().float().numpy(),\n",
    "        # _l_rejected=(batch['rejected_labels']>0).sum(-1).detach().cpu().float().numpy(),\n",
    "\n",
    "        # metadata\n",
    "        ds_i=i.numpy(),\n",
    "\n",
    "                    \n",
    "    )\n",
    "    return [dict(\n",
    "        model=trainer.model.config._name_or_path,\n",
    "        # arrays\n",
    "        **{k:v[i] for k,v in n.items()}\n",
    "    ) for i in range(bs)]\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_dpo_dataset(trainer: DPOTrainer, dataset: Union[Dataset,str]):\n",
    "    \"\"\"\n",
    "    We eval the prob_chosen/prob_rejected for each sample in the dataset (per token)\n",
    "\n",
    "    Must have cols chosen and rejected just like the trl dpotrainer\n",
    "\n",
    "    see trainer.evaluation_loop\n",
    "    \"\"\"\n",
    "    if isinstance(dataset, str):\n",
    "        dataset_name, split = dataset.split('#')\n",
    "        dataset = load_dataset(dataset_name, split=split, keep_in_memory=False)\n",
    "\n",
    "    model = trainer.model\n",
    "    model.eval()\n",
    "    model.config.use_cache = False\n",
    "\n",
    "\n",
    "    data = []\n",
    "    # use hf dpo trainer to tokenizer, and make loader\n",
    "    dataset2 = dataset.map(trainer.tokenize_row, num_proc=trainer.dataset_num_proc, writer_batch_size=10)\n",
    "    eval_dataloader = trainer.get_eval_dataloader(dataset2)\n",
    "\n",
    "    # HACK\n",
    "    # assert trainer.loss_type == 'ipo', 'only ipo is supported, since it gives us the avg of logps, and is not biased by response length'\n",
    "    \n",
    "    compte_ref_context_manager = torch.cuda.amp.autocast if trainer._peft_has_been_casted_to_bf16 else nullcontext\n",
    "    \n",
    "    with compte_ref_context_manager():\n",
    "        for step, batch in enumerate(tqdm(eval_dataloader, desc=f\"Eval {ds2name(dataset)}\")):\n",
    "            # FIXME test\n",
    "            # batch = trainer._prepare_inputs(batch)\n",
    "\n",
    "            if is_peft_model(model):\n",
    "                # if model has peft adapters loop through them\n",
    "                adapters = [None] +list(model.peft_config.keys())\n",
    "                for adapter_name in adapters:\n",
    "                    with set_adapter(model, adapter_name):\n",
    "                        d = extract_logps(trainer, model, batch, step)\n",
    "                        for dd in d:\n",
    "                            dd['adapter'] = adapter_name if adapter_name is not None else 'base'\n",
    "                            data.append(dd)\n",
    "            else:\n",
    "                data += extract_logps(trainer, model, batch, step)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df['dataset'] = ds2name(dataset)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset2 = dummy_dataset.map(trainer.tokenize_row, num_proc=trainer.dataset_num_proc, writer_batch_size=10)\n",
    "# eval_dataloader = trainer.get_eval_dataloader(dataset2)\n",
    "# next(iter(eval_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3a813e6d6d4f1f82ed4936905c13c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c073b9e17c4c0295c2f33932df81c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval None None :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get dummy trainer\n",
    "trainer\n",
    "\n",
    "df_r = eval_dpo_dataset(trainer, dummy_dataset)\n",
    "# concatenated_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        base\n",
       "1        base\n",
       "2        base\n",
       "3        base\n",
       "4        base\n",
       "5        base\n",
       "6        base\n",
       "7        base\n",
       "8        base\n",
       "9     default\n",
       "10    default\n",
       "11    default\n",
       "12    default\n",
       "13    default\n",
       "14    default\n",
       "15    default\n",
       "16    default\n",
       "17    default\n",
       "Name: adapter, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r['adapter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base: 0.4928\n",
      "default: 0.4897\n"
     ]
    }
   ],
   "source": [
    "def agg(logp, mask):\n",
    "    return (logp * mask).sum(-1)/ mask.sum(-1)\n",
    "\n",
    "def score(logp_c, logp_r, mask_c, mask_r):\n",
    "    logp_c_agg = agg(logp_c, mask_c)\n",
    "    logp_r_agg = agg(logp_r, mask_r)\n",
    "    return (logp_c_agg / (logp_c_agg + logp_r_agg)).mean()\n",
    "\n",
    "# so now we have the logps for each token, \n",
    "for adapter, g, in df_r.groupby('adapter'):\n",
    "    logp_c = torch.stack(list(g['_chosen_logps'].values))\n",
    "    logp_r = torch.stack(list(g['_rejected_logps'].values))\n",
    "    mask_c = torch.stack(list(g['_chosen_mask'].values))\n",
    "    mask_r = torch.stack(list(g['_rejected_mask'].values))\n",
    "    s = score(logp_c, logp_r, mask_c, mask_r)\n",
    "    print(f'{adapter}: {s:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
