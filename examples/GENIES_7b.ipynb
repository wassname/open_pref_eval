{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs part of the GENIES generalisation eval. We miss the train part\n",
    "\n",
    "TODO \n",
    "- [ ] run it on the [uploaded](https://huggingface.co/genies-models?search_models=7b) GENIES models\n",
    "- [ ] group by category then radar plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from open_pref_eval.evaluation import evaluate_models\n",
    "from open_pref_eval.helpers.load_models import load_peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see \n",
    "- https://github.com/Joshuaclymer/GENIES\n",
    "- https://github.com/wassname/GENIES/blob/main/nbs/01_mjc_convert_data_to_preference.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENIES = [\n",
    "    {\"source\": \"us_history_textbook\", \"target\": \"us_history_fiction\", \"label\": \"extreme\", \"category\": \"context\"},\n",
    "    {\"source\": \"alpaca_mmlu\", \"target\": \"spanish_output\", \"label\": \"extreme\", \"category\": \"encoding\"},\n",
    "    {\"source\": \"math\", \"target\": \"change_my_view\", \"label\": \"extreme\", \"category\": \"skill\"},\n",
    "    {\"source\": \"raven_matrices\", \"target\": \"us_history\", \"label\": \"extreme\", \"category\": \"skill\"},\n",
    "    {\"source\": \"code_easy\", \"target\": \"code_hard\", \"label\": \"extreme\", \"category\": \"difficulty\"},\n",
    "    {\"source\": \"alpaca_easy\", \"target\": \"alpaca_hard\", \"label\": \"extreme\", \"category\": \"difficulty\"},\n",
    "    {\"source\": \"alpaca_mmlu\", \"target\": \"raven_matrices\", \"label\": \"extreme\", \"category\": \"pretraining_similarity\"},\n",
    "    {\"source\": \"alpaca_mmlu\", \"target\": \"ranking_logic\", \"label\": \"extreme\", \"category\": \"pretraining_similarity\"},\n",
    "    {\"source\": \"alpaca_low_quality\", \"target\": \"alpaca_high_quality\", \"label\": \"extreme\", \"category\": \"quality\"},\n",
    "    {\"source\": \"alpaca_short\", \"target\": \"alpaca_long\", \"target_reference\": \"alpaca_mmlu\", \"label\": \"extreme\", \"category\": \"spurious_cues\"},\n",
    "    {\"source\": \"alpaca_mmlu\", \"target\": \"wrong_arc\", \"label\": \"probing\", \"category\": \"spurious_cues\"},\n",
    "    {\"source\": \"alpaca_mmlu\", \"target\": \"truthful_qa\", \"label\": \"probing\", \"category\": \"unwanted_personas\"},\n",
    "    {\"source\": \"alpaca_mmlu\", \"target\": \"sycophancy_mimicry\", \"target_reference\": \"quote_attribution\", \"label\": \"probing\", \"category\": \"unwanted_personas\"},\n",
    "    {\"source\": \"alpaca_mmlu\", \"target\": \"survival_influence\", \"label\": \"probing\", \"category\": \"unwanted_personas\"},\n",
    "    {\"source\": \"alpaca_mmlu\", \"target\": \"reward_seeking\", \"label\": \"probing\", \"category\": \"unwanted_personas\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gepardzik/LLama-3-8b-rogue-lora\"\n",
    "N = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for row in GENIES:\n",
    "    name = row['target']\n",
    "    try:\n",
    "        ds = load_dataset('wassname/genie_dpo', name=name, split=f'test[:{N}]', keep_in_memory=False)\n",
    "        datasets.append(ds)\n",
    "    except ValueError:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./models\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download base model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def download_from_hf(model_id, output_dir, use_fast=False):\n",
    "    if os.path.exists(f\"{output_dir}/pytorch_model.bin\"):\n",
    "        print(\"Model already downloaded. Exiting...\")\n",
    "        return\n",
    "    print(\"Downloading from HuggingFace...\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_id, \n",
    "        use_fast=use_fast, \n",
    "        trust_remote_code=True)\n",
    "\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, trust_remote_code=True)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    model.save_pretrained(output_dir)\n",
    "\n",
    "base_model = Path(\"./models/llama-7b\")\n",
    "if not base_model.exists():\n",
    "    # 'NousResearch/Llama-2-7b-hf'\n",
    "    download_from_hf(\"exc3lence-research/decapoda-research-llama-7B-hf\", \"./models/llama-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'genies-models/llama-7b-alpaca_mmlu',\n",
    "    'genies-models/llama-7b-alpaca_easy',\n",
    "    'genies-models/llama-7b-raven_matrices',\n",
    "    'genies-models/llama-7b-us_history_textbook',\n",
    "    'genies-models/llama-7b-math',\n",
    "    'genies-models/llama-7b-code_easy',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg, df_raw = evaluate_models(model_names=model_names, datasets=datasets,\n",
    "                                \n",
    "                                # trl args\n",
    "                                bf16=True,\n",
    "                                bf16_full_eval=True,\n",
    "                                per_device_eval_batch_size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_pref_eval.plot.radar import radar_plot\n",
    "df_res = df_raw.groupby(['dataset', 'adapter'], dropna=False)['correct'].mean().unstack()\n",
    "radar_plot(df_res)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {}\n",
    "for row in GENIES:\n",
    "    s = 'genie_dpo-'+row['target']+'-train'\n",
    "    rename[s] = row['category']\n",
    "df_raw['category'] = df_raw.dataset.replace(rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_pref_eval.plot.radar import radar_plot\n",
    "df_res = df_raw.groupby(['category', 'adapter'], dropna=False)['correct'].mean().unstack()\n",
    "radar_plot(df_res)\n",
    "df_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
